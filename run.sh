python train_mlm_flax_copy.py \
    --output_dir="./output_dir" \
    --overwrite_output_dir true \
    --validation_split_percentage 0.1 \
    --do_train \
    --do_eval \
    --per_device_train_batch_size="256" \
    --per_device_eval_batch_size="256" \
    --learning_rate="1e-3" \
    --num_train_epochs 4 \
    --warmup_steps="3000" \
    --logging_steps="10" \
    --save_steps="5000" \
    --eval_steps="5000" \
    --seed="42" \
    --config_name="albert_config.json" \
    --tokenizer_name="./bpe-tokenizer-ka" \
    --dtype="float16" \
    --token="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" \
    --dataset_name="uonlp/CulturaX" \
    --dataset_config_name="ka" \
    --max_seq_length="64" \
    --preprocessing_num_workers="14" \
    --overwrite_cache true