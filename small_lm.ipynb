{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import TransformerLM\n",
    "from src.trainer import (\n",
    "    create_learning_rate_schedule,\n",
    "    setup_initial_state\n",
    ")\n",
    "from src.steps import train_step, eval_step\n",
    "import optax\n",
    "import jax\n",
    "from flax import nnx\n",
    "from jax import random\n",
    "from flax.training import common_utils\n",
    "from tqdm import tqdm\n",
    "from src.confings import TransformerConfig, TrainerConfig\n",
    "from jax.experimental import mesh_utils\n",
    "from jax.sharding import Mesh, NamedSharding\n",
    "from jax.sharding import PartitionSpec as P\n",
    "from datasets import load_dataset\n",
    "import jax.numpy as jnp\n",
    "from itertools import chain\n",
    "from flax.training import checkpoints\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "import jax.random as random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const(config, key):\n",
    "    return TransformerLM(config, rngs=nnx.Rngs(params=key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = TrainerConfig()\n",
    "transformer_config = TransformerConfig(vocab_size=30_000, emb_dim=256, num_heads=4,\n",
    "                                        num_layers=3, qkv_dim=256, mlp_dim=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_devices = mesh_utils.create_device_mesh([1, 1, 1])\n",
    "mesh = Mesh(mesh_devices, ('data', 'fsdp', 'tensor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_fn = create_learning_rate_schedule(\n",
    "    learning_rate=trainer_config.learning_rate, warmup_steps=trainer_config.warmup_steps\n",
    ")\n",
    "tx = optax.adamw(learning_rate_fn, b1=0.9, b2=0.98, eps=1e-9,\n",
    "                  weight_decay=trainer_config.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_step = 0\n",
    "rng = jax.random.PRNGKey(42)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "rng, inference_rng = random.split(rng)\n",
    "dropout_rngs = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state, state_sharding = setup_initial_state(\n",
    "    const, tx, transformer_config, init_rng, mesh\n",
    ")\n",
    "\n",
    "data_sharding = NamedSharding(mesh, P(('data',)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jit_train_step = jax.jit(\n",
    "    train_step,\n",
    "    in_shardings=(state_sharding, data_sharding, None),\n",
    "    out_shardings=(state_sharding, None),\n",
    "    static_argnums=(2, 3),\n",
    "    donate_argnums=0\n",
    ")\n",
    "\n",
    "jit_eval_step = jax.jit(\n",
    "    eval_step,\n",
    "    in_shardings=(\n",
    "      state_sharding.params,\n",
    "      data_sharding,\n",
    "    ),  # type: ignore\n",
    "    out_shardings=None,  # type: ignore\n",
    "    static_argnums=(2, 3),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_hf = PreTrainedTokenizerFast.from_pretrained('ZurabDz/bpe_tokenizer_tmp', token='<>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349c8f619ef744af9d213fe666ad9eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d2721da15f4118b9d32cf98da8d0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c0272f0c34609961dc5f0dbe3934f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('DKYoon/SlimPajama-6B', num_proc=6, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 500_000\n",
    "small_dataset = dataset.select(range(0, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_pad(batch):\n",
    "    return {'ids': tokenizer_hf(batch['text'])['input_ids']}\n",
    "\n",
    "def group_texts(examples, block_size=128):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: list(chain(*examples[k])) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "    # customize this part to your needs.\n",
    "    if total_length >= block_size:\n",
    "        total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_dataset = small_dataset.map(tokenize_and_pad, batched=True, num_proc=8, remove_columns=small_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = mapped_dataset.map(group_texts, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 80\n",
    "iter_ds = grouped.iter(batch_size)\n",
    "train_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 48/51228 [00:16<4:58:00,  2.86it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mStepTraceAnnotation(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep):\n\u001b[1;32m      4\u001b[0m   batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(iter_ds)\n\u001b[0;32m----> 5\u001b[0m   jaxed_batch \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m   state, metrics \u001b[38;5;241m=\u001b[39m jit_train_step(\n\u001b[1;32m      7\u001b[0m     state, jaxed_batch, learning_rate_fn, \u001b[38;5;241m0.0\u001b[39m, dropout_rngs\n\u001b[1;32m      8\u001b[0m   )\n\u001b[1;32m      9\u001b[0m   train_metrics\u001b[38;5;241m.\u001b[39mappend(metrics)\n",
      "File \u001b[0;32m~/micromamba/envs/microlm/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:5633\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin, device)\u001b[0m\n\u001b[1;32m   5629\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(dtype, allow_extended_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   5631\u001b[0m out: ArrayLike\n\u001b[0;32m-> 5633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mArray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleaf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mleaves\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   5634\u001b[0m   \u001b[38;5;66;03m# TODO(jakevdp): falling back to numpy here fails to overflow for lists\u001b[39;00m\n\u001b[1;32m   5635\u001b[0m   \u001b[38;5;66;03m# containing large integers; see discussion in\u001b[39;00m\n\u001b[1;32m   5636\u001b[0m   \u001b[38;5;66;03m# https://github.com/jax-ml/jax/pull/6047. More correct would be to call\u001b[39;00m\n\u001b[1;32m   5637\u001b[0m   \u001b[38;5;66;03m# coerce_to_array on each leaf, but this may have performance implications.\u001b[39;00m\n\u001b[1;32m   5638\u001b[0m   out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mobject\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   5639\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, Array):\n",
      "File \u001b[0;32m~/micromamba/envs/microlm/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:5633\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5629\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(dtype, allow_extended_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   5631\u001b[0m out: ArrayLike\n\u001b[0;32m-> 5633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mleaf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mArray\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m leaf \u001b[38;5;129;01min\u001b[39;00m leaves):\n\u001b[1;32m   5634\u001b[0m   \u001b[38;5;66;03m# TODO(jakevdp): falling back to numpy here fails to overflow for lists\u001b[39;00m\n\u001b[1;32m   5635\u001b[0m   \u001b[38;5;66;03m# containing large integers; see discussion in\u001b[39;00m\n\u001b[1;32m   5636\u001b[0m   \u001b[38;5;66;03m# https://github.com/jax-ml/jax/pull/6047. More correct would be to call\u001b[39;00m\n\u001b[1;32m   5637\u001b[0m   \u001b[38;5;66;03m# coerce_to_array on each leaf, but this may have performance implications.\u001b[39;00m\n\u001b[1;32m   5638\u001b[0m   out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mobject\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   5639\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, Array):\n",
      "File \u001b[0;32m<frozen abc>:119\u001b[0m, in \u001b[0;36m__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for step in tqdm(range(start_step, len(grouped) // batch_size)):\n",
    "    batch = next(iter_ds)\n",
    "    jaxed_batch = jnp.array(batch['ids'])\n",
    "    state, metrics = jit_train_step(\n",
    "        state, jaxed_batch, learning_rate_fn, 0.0, dropout_rngs\n",
    "    )\n",
    "    train_metrics.append(metrics)\n",
    "\n",
    "    if step % 500 == 0:\n",
    "        train_metrics = common_utils.stack_forest(train_metrics)\n",
    "        lr = train_metrics.pop('learning_rate').mean()\n",
    "        metrics_sums = jax.tree.map(jnp.sum, train_metrics)\n",
    "        denominator = metrics_sums.pop('denominator')\n",
    "        summary = jax.tree.map(lambda x: x / denominator, metrics_sums)  # pylint: disable=cell-var-from-loop\n",
    "        summary['learning_rate'] = lr\n",
    "        summary['perplexity'] = jnp.clip(jnp.exp(summary['loss']), max=1.0e4)\n",
    "        summary = {'train_' + k: v for k, v in summary.items()}\n",
    "        print(summary)\n",
    "        train_metrics = []\n",
    "\n",
    "    if step % 2000 == 0:\n",
    "        rng_params = state.rest['decoder']['encoderdecoderblock_0']['attention']['rngs']['params']\n",
    "        rng_params['key'].value = random.key_data(rng_params['key'].value)\n",
    "        checkpoints.save_checkpoint_multiprocess(trainer_config.output_dir, state, step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microlm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
